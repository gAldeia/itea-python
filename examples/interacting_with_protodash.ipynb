{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interacting with ProtoDash"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook we'll combine the ProtoDash and the Partial Effects to obtain feature importances on the digits classifications task.\n",
    "\n",
    "ProtoDash was proposed in _Gurumoorthy, Karthik & Dhurandhar, Amit & Cecchi, Guillermo & Aggarwal, Charu. (2019). Efficient Data Representation by Selecting Prototypes with Importance Weights. 260-269. 10.1109/ICDM.2019.00036_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy  as np\n",
    "import pandas as pd\n",
    "\n",
    "# automatically differentiable implementation of numpy\n",
    "import jax.numpy as jnp\n",
    "\n",
    "from sklearn import datasets\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from IPython.display         import display, Math, Latex\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from itea.classification import ITEA_classifier\n",
    "from itea.inspection     import *\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "from aix360.algorithms.protodash import ProtodashExplainer, get_Gaussian_Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1203, 64)\n",
      "gen \t min_fitness \t mean_fitness \t max_fitness \t remaining (s)\n",
      "0 \t 0.1055694098088113 \t 0.10556940980881134 \t 0.1055694098088113 \t 145min55seg\n",
      "5 \t 0.1055694098088113 \t 0.1057148794679967 \t 0.10640066500415628 \t 152min47seg\n",
      "10 \t 0.1055694098088113 \t 0.10751870324189525 \t 0.18121363258520365 \t 378min57seg\n",
      "15 \t 0.10640066500415628 \t 0.11966334164588527 \t 0.18786367414796343 \t 508min8seg\n",
      "20 \t 0.10640066500415628 \t 0.18519950124688278 \t 0.19201995012468828 \t 1209min42seg\n"
     ]
    }
   ],
   "source": [
    "digits_data = datasets.load_digits()\n",
    "\n",
    "X, y        = digits_data['data'], digits_data['target']\n",
    "labels      = digits_data['feature_names']\n",
    "targets     = digits_data['target_names']\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.33, random_state=42)\n",
    "\n",
    "print(X_train.shape)\n",
    "\n",
    "# Creating transformation functions for ITEA using jax.numpy\n",
    "# (so we don't need to analytically calculate its derivatives)\n",
    "tfuncs = {\n",
    "    'id'       : lambda x: x,\n",
    "    'log'      : jnp.log,\n",
    "    'exp'      : jnp.exp\n",
    "}\n",
    "\n",
    "clf = ITEA_classifier(\n",
    "    gens            = 1000,\n",
    "    popsize         = 200,\n",
    "    max_terms       = 64,\n",
    "    expolim         = (0, 1),\n",
    "    verbose         = 5,\n",
    "    tfuncs          = tfuncs,\n",
    "    labels          = labels,\n",
    "    simplify_method = 'simplify_by_var',\n",
    "    random_state    = 42,\n",
    ").fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_itexpr = clf.bestsol_\n",
    "final_itexpr.selected_features_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_test.shape, y_test.reshape(-1, 1).shape)\n",
    "\n",
    "onehot_encoder = OneHotEncoder(sparse=False)\n",
    "onehot_encoded = onehot_encoder.fit_transform(\n",
    "    np.hstack( (X_train, y_train.reshape(-1, 1)) ) )\n",
    "\n",
    "explainer = ProtodashExplainer()\n",
    "\n",
    "# call protodash explainer\n",
    "# S contains indices of the selected prototypes\n",
    "# W contains importance weights associated with the selected prototypes \n",
    "(W, S, _) = explainer.explain(onehot_encoded, onehot_encoded, m=len(np.unique(y_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2, 3, figsize=(8,5))\n",
    "\n",
    "# Hiding one subplot\n",
    "axs[1, 2].set_visible(False)\n",
    "\n",
    "for s, ax in zip(S, fig.axes):\n",
    "    ax.imshow(X_train[s].reshape(8, 8))\n",
    "    ax.set_title(f\"Prototype of class {y_train[s]}\")\n",
    "    \n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "it_explainer = ITExpr_explainer(\n",
    "    itexpr=final_itexpr,\n",
    "    tfuncs=tfuncs\n",
    ").fit(X_train, y_train)\n",
    "\n",
    "fig, axs = plt.subplots(2, 3, figsize=(8,5))\n",
    "\n",
    "axs[1, 2].set_visible(False)\n",
    "\n",
    "for s, ax in zip(S, fig.axes):\n",
    "    \n",
    "    importances = np.sum(\n",
    "        it_explainer.average_partial_effects(X_train[s, :].reshape(1, -1)),\n",
    "        axis=0\n",
    "    )\n",
    "    \n",
    "    ax.imshow(importances.reshape(8, 8))\n",
    "    ax.set_title(f\"Feature importances for\\nPrototype of class {y_train[s]}\")\n",
    "    \n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now lets pick multiple prototypes and see the feature importance for groups\n",
    "\n",
    "explainer = ProtodashExplainer()\n",
    "\n",
    "(W, S, _) = explainer.explain(onehot_encoded, onehot_encoded, m=len(np.unique(y_train))*3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2, 3, figsize=(8,5))\n",
    "\n",
    "axs[1, 2].set_visible(False)\n",
    "\n",
    "for class_, ax in zip(np.unique(y_train), fig.axes):\n",
    "    \n",
    "    prototypes_for_class = [s for s in S if y_train[s]==class_]\n",
    "    \n",
    "    importances = it_explainer.average_partial_effects(X_train[prototypes_for_class, :])[class_]\n",
    "    \n",
    "    ax.imshow(importances.reshape(8, 8))\n",
    "    ax.set_title(f\"Feature importances for\\nPrototype of class {class_}\")\n",
    "    \n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
