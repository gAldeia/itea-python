{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b7476644",
   "metadata": {},
   "source": [
    "# Recreating the Scikit-learn LogisticRegression method\n",
    "\n",
    "In this notebook I'm going to re-create the logistic regression without the overhead of checks that scikit-learn method performs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "7d3196e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from itea.classification  import ITEA_classifier\n",
    "\n",
    "from sklearn.datasets import make_blobs\n",
    "\n",
    "tfuncs    = {'id' : lambda x: x}\n",
    "tfuncs_dx = {'id' : lambda x: np.ones_like(x),}\n",
    "\n",
    "# Classification execution\n",
    "X_clf, y_clf = make_blobs(\n",
    "    n_samples    = 100,\n",
    "    n_features   = 2,\n",
    "    cluster_std  = 1,\n",
    "    centers      = [(-10,-10), (0,0), (10, 10)],\n",
    "    random_state = 0,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "36404fae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.004296302795410156\n",
      "[[-0.55009618 -0.60745217]\n",
      " [-0.08147184  0.11412668]\n",
      " [ 0.63156802  0.4933255 ]]\n",
      "[-1.26197799  2.81647098 -1.55449298]\n",
      "[0 1 2]\n",
      "[100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/galdeia/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "# First, the original method\n",
    "\n",
    "exectime_ = time.time()\n",
    "clf_original = LogisticRegression(solver='saga', penalty='none').fit(X_clf, y_clf)\n",
    "exectime_ = time.time() - exectime_\n",
    "\n",
    "print(exectime_)\n",
    "print(clf_original.coef_)\n",
    "print(clf_original.intercept_)\n",
    "print(clf_original.classes_)\n",
    "print(clf_original.n_iter_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "44b1fb14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0028505325317382812\n",
      "[[-0.55362482 -0.60421306]\n",
      " [-0.07915516  0.11205122]\n",
      " [ 0.63277998  0.49216185]]\n",
      "[-1.26707532  2.81774843 -1.55067311]\n",
      "[0 1 2]\n",
      "100\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model._sag import sag_solver\n",
    "from sklearn.preprocessing import LabelEncoder, LabelBinarizer\n",
    "from sklearn.utils.extmath import row_norms\n",
    "\n",
    "def my_implementation(X, y):\n",
    "    classes_ = np.unique(y)\n",
    "    \n",
    "    n_classes = len(classes_)\n",
    "    n_features = X.shape[1]\n",
    "    \n",
    "    max_squared_sum = row_norms(X, squared=True).max()\n",
    "\n",
    "    if n_classes > 2:\n",
    "        multi_class = 'multinomial'\n",
    "        \n",
    "        # SAG multinomial solver needs LabelEncoder, not LabelBinarizer\n",
    "        le = LabelEncoder()\n",
    "        Y_multi = le.fit_transform(y).astype(X.dtype, copy=False)\n",
    "\n",
    "        target = Y_multi.astype(X.dtype, copy=False)\n",
    "        w0 = np.zeros((classes_.size, n_features + 1),\n",
    "                      order='F', dtype=X.dtype)\n",
    "        \n",
    "        warm_start = {'coef': w0.T}\n",
    "    else:\n",
    "        multi_class = 'log'\n",
    "        w0 = np.zeros(n_features + 1, dtype=X.dtype)\n",
    "        \n",
    "        mask = (y == classes_[1])\n",
    "        n_classes -= 1\n",
    "        \n",
    "        y_bin = np.ones(y.shape, dtype=X.dtype)\n",
    "        y_bin[~mask] = -1.\n",
    "        \n",
    "        target = y_bin\n",
    "        warm_start = {'coef': np.expand_dims(w0, axis=1)}\n",
    "    \n",
    "    coef_, n_iter_, _ = sag_solver(\n",
    "        X, target, sample_weight=None, loss=multi_class, alpha=0., beta=0.,\n",
    "        max_iter=100, tol=0.001, verbose=0, random_state=None,\n",
    "        check_input=False, max_squared_sum=max_squared_sum,\n",
    "        warm_start_mem=warm_start,\n",
    "        is_saga=True)\n",
    "    \n",
    "    if n_classes <= 2:\n",
    "        coef_ = coef_.reshape(n_classes, n_features + 1)\n",
    "    \n",
    "    intercept_ = coef_[:, -1]\n",
    "    coef_      = coef_[:, :-1]\n",
    "\n",
    "    return coef_, intercept_, classes_, n_iter_\n",
    "\n",
    "exectime_ = time.time()\n",
    "coef_, intercept_, classes_, n_iter_ = my_implementation(X_clf, y_clf)\n",
    "exectime_ = time.time() - exectime_\n",
    "\n",
    "print(exectime_)\n",
    "print(coef_)\n",
    "print(intercept_)\n",
    "print(classes_)\n",
    "print(n_iter_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0f1417c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
