{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Iris classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook will walk through the process of using the ITEA for classification (``ITEA_classifier``) and interpreting the final expression with the ``itea.inspection`` tools."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy  as np\n",
    "import pandas as pd\n",
    "\n",
    "# automatically differentiable implementation of numpy\n",
    "import jax.numpy as jnp\n",
    "\n",
    "from sklearn import datasets\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from IPython.display         import display, Math, Latex\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from itea.classification import ITEA_classifier\n",
    "from itea.inspection     import *\n",
    "\n",
    "import warnings; warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use the Iris data set in this example.\n",
    "\n",
    "This data set contains 3 different classes of Iris flowers and has 4 features: sepal width, sepal length, petal width, and petal length.\n",
    "\n",
    "One example of each flower is illustrated in the figure below.\n",
    "\n",
    "![](https://s3.amazonaws.com/assets.datacamp.com/blog_assets/Machine+Learning+R/iris-machinelearning.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating and fitting an ``ITEA_classifier``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gen \t min_fitness \t mean_fitness \t max_fitness \t remaining (s)\n",
      "0 \t 0.56 \t 0.8482 \t 0.97 \t 0min17seg\n",
      "5 \t 0.74 \t 0.9617999999999999 \t 0.98 \t 0min11seg\n",
      "10 \t 0.79 \t 0.9693999999999999 \t 0.99 \t 0min11seg\n",
      "15 \t 0.95 \t 0.9822 \t 0.99 \t 0min9seg\n",
      "20 \t 0.89 \t 0.9822 \t 0.99 \t 0min9seg\n",
      "25 \t 0.86 \t 0.9824 \t 0.99 \t 0min8seg\n",
      "30 \t 0.93 \t 0.9818000000000001 \t 0.99 \t 0min6seg\n",
      "35 \t 0.96 \t 0.9826000000000001 \t 0.99 \t 0min4seg\n",
      "40 \t 0.94 \t 0.9816000000000001 \t 0.99 \t 0min3seg\n",
      "45 \t 0.66 \t 0.9738 \t 0.99 \t 0min1seg\n"
     ]
    }
   ],
   "source": [
    "iris_data = datasets.load_iris()\n",
    "X, y      = iris_data['data'], iris_data['target']\n",
    "labels    = iris_data['feature_names']\n",
    "targets   = iris_data['target_names']\n",
    "\n",
    "# changing numbers to the class names\n",
    "y_targets = [targets[yi] for yi in y]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y_targets, test_size=0.33, random_state=42)\n",
    "\n",
    "# Creating transformation functions for ITEA using jax.numpy\n",
    "# (so we don't need to analytically calculate its derivatives)\n",
    "tfuncs = {\n",
    "    'id'       : lambda x: x,\n",
    "    'sqrt.abs' : lambda x: jnp.sqrt(jnp.abs(x)), \n",
    "    'log'      : jnp.log,\n",
    "    'exp'      : jnp.exp\n",
    "}\n",
    "\n",
    "clf = ITEA_classifier(\n",
    "    gens            = 50,\n",
    "    popsize         = 50,\n",
    "    max_terms       = 2,\n",
    "    expolim         = (-1, 1),\n",
    "    verbose         = 5,\n",
    "    tfuncs          = tfuncs,\n",
    "    labels          = labels,\n",
    "    simplify_method = 'simplify_by_var',\n",
    "    fit_kw          = {'max_iter':25},\n",
    "    random_state    = 42,\n",
    ").fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the ``ITEA_classifier`` and the best solution found by the ITEA ``ITExpr_classifier`` are both scikit-like models, we can use some base methods like ``get_params``:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'ITExpr_classifier' object has no attribute 'alpha'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-b8a20b96219b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbestsol_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36mget_params\u001b[0;34m(self, deep)\u001b[0m\n\u001b[1;32m    193\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_param_names\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 195\u001b[0;31m             \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    196\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mdeep\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'get_params'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m                 \u001b[0mdeep_items\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'ITExpr_classifier' object has no attribute 'alpha'"
     ]
    }
   ],
   "source": [
    "clf.bestsol_.get_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inspecting the results from ``ITEA_classifier`` and ``ITExpr_classifier``\n",
    "\n",
    "Now that we have fitted the ITEA, our ``clf`` contains the ``bestsol_`` attribute, which is a fitted instance of ``ITExpr_classifier`` ready to be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_itexpr = clf.bestsol_\n",
    "\n",
    "final_itexpr.to_str(term_separator='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(\n",
    "    y_test,\n",
    "    final_itexpr.predict(X_test),\n",
    "    target_names=targets\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use the ``ITExpr_inspector`` to obtain metrics regarding the IT terms in the expression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(pd.DataFrame(\n",
    "    ITExpr_inspector(\n",
    "        itexpr=final_itexpr, tfuncs=tfuncs\n",
    "    ).fit(X_train, y_train).terms_analysis()\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By using the ``ITExpr_texifier``, we can create formatted LaTeX strings of the final expression and its derivatives."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The final expression\n",
    "display(Latex(\n",
    "    '$ ITExpr = ' + ITExpr_texifier.to_latex(\n",
    "        final_itexpr,\n",
    "        term_wrapper=lambda i, term: r'\\underbrace{' + term + r'}_{\\text{term ' + str(i) + '}}'\n",
    "    ) + '$'\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List containing the partial derivatives\n",
    "derivatives_latex = ITExpr_texifier.derivatives_to_latex(\n",
    "    final_itexpr,\n",
    "    term_wrapper=lambda i, term: r'\\underbrace{' + term + r'}_{\\text{term ' + str(i) + r' partial derivative}}'\n",
    ")\n",
    "\n",
    "# displaying one of its derivatives\n",
    "display(Latex(\n",
    "    r'$ \\frac{\\partial}{\\partial ' + labels[0] + '} ITExpr = ' + derivatives_latex[0] + '$'\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explaining the ``IT_classifier`` expression using Partial Effects\n",
    "\n",
    "Now let's create an instance of ``ITExpr_explainer``.\n",
    "\n",
    "We can calculate feature importances with Partial Effects (PE) or approximate the Shapley values using PE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "explainer = ITExpr_explainer(\n",
    "    itexpr=final_itexpr,\n",
    "    tfuncs=tfuncs\n",
    ").fit(X_train, y_train)\n",
    "\n",
    "explainer.plot_feature_importances(\n",
    "    X = X_train,\n",
    "    importance_method = 'pe', # change to 'shapley'\n",
    "    grouping_threshold = 0.0,\n",
    "    target = None,\n",
    "    barh_kw = {'edgecolor' : 'k'},\n",
    "    show = True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can explain a single instance as well:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer.plot_feature_importances(\n",
    "    X = X_test[0, :].reshape(1, -1),\n",
    "    importance_method = 'pe', # change to 'shapley'\n",
    "    grouping_threshold = 0.0,\n",
    "    target = None,\n",
    "    barh_kw = {'edgecolor' : 'k'},\n",
    "    show = True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead of looking into the average Partial Effects, we can plot the Partial Effects for each variable when its co-variables are fixed at the means."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 4, figsize=(16, 4))\n",
    "\n",
    "explainer.plot_partial_effects_at_means(\n",
    "    X          = X_test, # Obtaining explanations for test data \n",
    "    ax         = axs,\n",
    "    features   = final_itexpr.labels,\n",
    "    target     = None,\n",
    "    num_points = 100,\n",
    "    share_y    = False,\n",
    "    show_err   = False,\n",
    "    show       = False,\n",
    ")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can share the y axis and show errors hatchs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 4, figsize=(16, 4))\n",
    "\n",
    "explainer.plot_partial_effects_at_means(\n",
    "    X          = X_test, # Obtaining explanations for test data \n",
    "    ax         = axs,\n",
    "    features   = final_itexpr.labels,\n",
    "    target     = None,\n",
    "    num_points = 100,\n",
    "    share_y    = True,\n",
    "    show_err   = True,\n",
    "    show       = False,\n",
    ")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
