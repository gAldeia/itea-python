{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0b60463b",
   "metadata": {},
   "source": [
    "# Recreating the Scikit-learn LogisticRegression method\n",
    "\n",
    "In this notebook I'm going to re-create the logistic regression without the overhead of checks that scikit-learn method performs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "32a45910",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.utils.extmath import softmax\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from itea.classification  import ITEA_classifier\n",
    "\n",
    "from sklearn.datasets import make_blobs\n",
    "\n",
    "tfuncs    = {'id' : lambda x: x}\n",
    "tfuncs_dx = {'id' : lambda x: np.ones_like(x),}\n",
    "\n",
    "# Classification execution\n",
    "X_clf, y_clf = make_blobs(\n",
    "    n_samples    = 100,\n",
    "    n_features   = 2,\n",
    "    cluster_std  = 1,\n",
    "    centers      = [(-10,-10), (10, 10)],\n",
    "    random_state = 0,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "a4836c67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0022547245025634766\n",
      "[[0.48337368 0.51733756]]\n",
      "[0.00588424]\n",
      "[0 1]\n",
      "[100]\n",
      "[[9.99940572e-01 5.94275638e-05]\n",
      " [1.93190907e-04 9.99806809e-01]]\n",
      "[0 1 0 1 1 0 0 1 0 0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/galdeia/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "# First, the original method\n",
    "\n",
    "exectime_ = time.time()\n",
    "clf_original = LogisticRegression(solver='saga', penalty='none').fit(X_clf, y_clf)\n",
    "exectime_ = time.time() - exectime_\n",
    "\n",
    "print(exectime_)\n",
    "print(clf_original.coef_)\n",
    "print(clf_original.intercept_)\n",
    "print(clf_original.classes_)\n",
    "print(clf_original.n_iter_)\n",
    "print(clf_original.predict_proba(X_clf[:2, :]))\n",
    "print(clf_original.predict(X_clf[:10, :]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "0b6337d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0012922286987304688\n",
      "[[0.46814302 0.50734168]]\n",
      "[-0.02233791]\n",
      "[0 1]\n",
      "97\n",
      "[[9.99999998e-01 2.00909890e-09]\n",
      " [1.66818863e-07 9.99999833e-01]]\n",
      "[0 1 0 1 1 0 0 1 0 0]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model._sag import sag_solver\n",
    "from sklearn.preprocessing import LabelEncoder, LabelBinarizer\n",
    "from sklearn.utils.extmath import row_norms, safe_sparse_dot\n",
    "from scipy.special import expit\n",
    "\n",
    "def my_implementation(X, y):\n",
    "    classes_  = np.unique(y)\n",
    "    \n",
    "    Z = X # Nosso Z seria o eval\n",
    "    \n",
    "    n_classes  = len(classes_)\n",
    "    n_terms = Z.shape[1]\n",
    "    \n",
    "    max_squared_sum = row_norms(Z, squared=True).max()\n",
    "\n",
    "    if n_classes > 2:\n",
    "        multi_class = 'multinomial'\n",
    "            \n",
    "        # from scikit: \"SAG multinomial solver needs LabelEncoder, not LabelBinarizer\"\n",
    "        target = LabelEncoder().fit_transform(y).astype(Z.dtype, copy=False)\n",
    "\n",
    "        w0 = np.zeros(\n",
    "            (classes_.size, n_terms + 1), order='F', dtype=Z.dtype)\n",
    "        \n",
    "        warm_start = {'coef': w0.T}\n",
    "    else:\n",
    "        multi_class = 'log'\n",
    "        \n",
    "        n_classes -= 1\n",
    "        \n",
    "        target = np.ones(y.shape, dtype=Z.dtype)\n",
    "        target[~(y == classes_[1])] = -1.\n",
    "        \n",
    "        w0 = np.zeros(n_terms + 1, dtype=Z.dtype)\n",
    "        \n",
    "        warm_start = {'coef': np.expand_dims(w0, axis=1)}\n",
    "    \n",
    "    coef_, n_iter_, _ = sag_solver(\n",
    "        Z, target, sample_weight=None, loss=multi_class, alpha=0., beta=0.,\n",
    "        max_iter=100, tol=0.001, verbose=0, random_state=None,\n",
    "        check_input=False, max_squared_sum=max_squared_sum,\n",
    "        warm_start_mem=warm_start, is_saga=True)\n",
    "    \n",
    "    if n_classes <= 2:\n",
    "        coef_ = coef_.reshape(n_classes, n_terms + 1)\n",
    "    \n",
    "    intercept_ = coef_[:, -1]\n",
    "    coef_      = coef_[:, :-1]\n",
    "\n",
    "    return coef_, intercept_, classes_, n_iter_\n",
    "\n",
    "\n",
    "\n",
    "def predict_proba(coef_, intercept_, classes_, X):\n",
    "    \n",
    "    prob = (\n",
    "        safe_sparse_dot(\n",
    "        X, # AQUI SERIA O EVAL Z\n",
    "        np.array(coef_).T\n",
    "    ) + np.array(intercept_))\n",
    "    \n",
    "    # Normalizar no caso multiclasse\n",
    "    if len(classes_) <= 2:\n",
    "        prob = np.hstack( (np.ones(X.shape[0]).reshape(-1, 1), prob) )  \n",
    "        prob[:, 0] -= prob[:, 1]\n",
    "    \n",
    "    return softmax(prob)\n",
    "        \n",
    "    \n",
    "def predict(coef_, intercept_, classes_, X):\n",
    "    probabilities = predict_proba(coef_, intercept_, classes_, X)\n",
    "\n",
    "    return np.array(classes_)[np.argmax(probabilities, axis=1)]\n",
    "\n",
    "\n",
    "exectime_ = time.time()\n",
    "coef_, intercept_, classes_, n_iter_ = my_implementation(X_clf, y_clf)\n",
    "exectime_ = time.time() - exectime_\n",
    "\n",
    "print(exectime_)\n",
    "print(coef_)\n",
    "print(intercept_)\n",
    "print(classes_)\n",
    "print(n_iter_)\n",
    "print(predict_proba(coef_, intercept_, classes_, X_clf[:2, :]))\n",
    "print(predict(coef_, intercept_, classes_, X_clf[:10, :]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "37c96790",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "print(np.array_equal(\n",
    "    predict(coef_, intercept_, classes_, X_clf),\n",
    "    clf_original.predict(X_clf)\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5582b915",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
