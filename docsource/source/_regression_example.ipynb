{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# California housing regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook we'll use the ``ITEA_regressor`` to search for a good expression, that will be encapsulated inside the  ``ITExpr_regressor`` class, and it will be used for the regression task of predicting California housing prices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy  as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn import datasets\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from IPython.display         import display\n",
    "\n",
    "from itea.regression import ITEA_regressor\n",
    "from itea.inspection import *\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore', module=r'itea')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The California Housing data set contains 8 features.\n",
    "\n",
    "In this notebook, we'll provide the transformation functions and their derivatives, instead of using the itea feature of extracting the derivatives using Jax."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating and fitting an ``ITEA_regressor``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gen | smallest fitness | mean fitness | highest fitness | remaining time\n",
      "----------------------------------------------------------------------------\n",
      "  0 |         0.879653 |     1.075671 |        1.153701 | 1min17sec   \n",
      " 10 |         0.794826 |     0.828574 |        0.983679 | 2min7sec    \n",
      " 20 |         0.788833 |     0.799124 |        0.850923 | 1min39sec   \n",
      " 30 |         0.740517 |     0.783561 |        0.806966 | 1min9sec    \n"
     ]
    }
   ],
   "source": [
    "housing_data = datasets.fetch_california_housing() \n",
    "X, y         = housing_data['data'], housing_data['target']\n",
    "labels       = housing_data['feature_names']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.33, random_state=42)\n",
    "\n",
    "tfuncs = {\n",
    "    'log'      : np.log,\n",
    "    'sqrt.abs' : lambda x: np.sqrt(np.abs(x)), \n",
    "    'id'       : lambda x: x,\n",
    "    'sin'      : np.sin,\n",
    "    'cos'      : np.cos,\n",
    "    'exp'      : np.exp\n",
    "}\n",
    "\n",
    "tfuncs_dx = {\n",
    "    'log'      : lambda x: 1/x,\n",
    "    'sqrt.abs' : lambda x: x/( 2*(np.abs(x)**(3/2)) ),\n",
    "    'id'       : lambda x: np.ones_like(x),\n",
    "    'sin'      : np.cos,\n",
    "    'cos'      : lambda x: -np.sin(x),\n",
    "    'exp'      : np.exp,\n",
    "}\n",
    "\n",
    "reg = ITEA_regressor(\n",
    "    gens         = 50,\n",
    "    popsize      = 50,\n",
    "    max_terms    = 5,\n",
    "    expolim      = (0, 2),\n",
    "    verbose      = 10,\n",
    "    tfuncs       = tfuncs,\n",
    "    tfuncs_dx    = tfuncs_dx,\n",
    "    labels       = labels,\n",
    "    random_state = 42,\n",
    "    simplify_method = 'simplify_by_coef'\n",
    ").fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inspecting the results from ``ITEA_regressor`` and ``ITExpr_regressor``\n",
    "\n",
    "We can see the convergence of the fitness, the number of terms, or tree complexity by using the ``ITEA_summarizer``, an inspector class focused on the ``ITEA``:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(3, 1, figsize=(10, 8), sharex=True)\n",
    "\n",
    "summarizer = ITEA_summarizer(itea=reg).fit(X_train, y_train)\n",
    "\n",
    "summarizer.plot_convergence(\n",
    "    data=['fitness', 'n_terms', 'complexity'],\n",
    "    ax=axs,\n",
    "    show=False\n",
    ")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have fitted the ITEA, our ``reg`` contains the ``bestsol_`` attribute, which is a fitted instance of ``ITExpr_regressor`` ready to be used. Let us see the final expression and the execution time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_itexpr = reg.bestsol_\n",
    "\n",
    "print('\\nFinal expression:\\n', final_itexpr.to_str(term_separator=' +\\n'))\n",
    "print(f'\\nElapsed time: {reg.exectime_}')\n",
    "print(f'\\nSelected Features: {final_itexpr.selected_features_}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# just remembering that ITEA and ITExpr implements scikits\n",
    "# base classes. We can check all parameters with:\n",
    "print(final_itexpr.get_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots()\n",
    "\n",
    "axs.scatter(y_test, final_itexpr.predict(X_test))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use the ``ITExpr_inspector`` to see information for each term."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(pd.DataFrame(\n",
    "    ITExpr_inspector(\n",
    "        itexpr=final_itexpr, tfuncs=tfuncs\n",
    "    ).fit(X_train, y_train).terms_analysis()\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explaining the ``IT_regressor`` expression using Partial Effects\n",
    "\n",
    "We can obtain feature importances using the Partial Effects and the ``ITExpr_explainer``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer = ITExpr_explainer(\n",
    "    itexpr=final_itexpr, tfuncs=tfuncs, tfuncs_dx=tfuncs_dx).fit(X, y)\n",
    "\n",
    "explainer.plot_feature_importances(\n",
    "    X=X_train,\n",
    "    importance_method='pe',\n",
    "    grouping_threshold=0.0,\n",
    "    barh_kw={'color':'green'}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Partial Effects at the Means can help understand how the contribution of each variable changes according to its values when their covariables are fixed at the means."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2, 4, figsize=(10, 5))\n",
    "\n",
    "explainer.plot_partial_effects_at_means(\n",
    "    X=X_test,\n",
    "    features=range(8),\n",
    "    ax=axs,\n",
    "    num_points=100,\n",
    "    share_y=False,\n",
    "    show_err=True,\n",
    "    show=False\n",
    ")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we can also plot the mean relative importances of each feature by calculating the average Partial Effect for each interval when the output is discretized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(10, 4))\n",
    "\n",
    "explainer.plot_normalized_partial_effects(\n",
    "    grouping_threshold=0.1, show=False,\n",
    "    num_points=100, ax=ax\n",
    ")\n",
    "\n",
    "plt.tight_layout()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
